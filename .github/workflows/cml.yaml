name: testing
on: [push]
jobs:
  run:
    runs-on: [self-hosted, big-gpu, cml]
    environment: test
    
    steps:
      - uses: actions/checkout@v2
      - uses: docker/login-action@v1
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}
      - name: cml_run
        shell: bash
        env:
          repo_token: ${{ secrets.GITHUB_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID}}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          MLFLOW_S3_ENDPOINT_URL: ${{ secrets.MLFLOW_S3_ENDPOINT_URL }}
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_TRACKING_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_TRACKING_PASSWORD }}
        run: |
          # Install requirements
          pip install dvc boto3

          ./build_image.sh

          # No need to install other reqs as runs are done in docker

          # Pull data & run-cache from S3 and reproduce pipeline
          dvc pull -d --run-cache train_siamese
          dvc repro train_siamese
          dvc push

          # Report metrics
          echo "## Metrics" >> report.md
          git fetch --prune
          dvc metrics diff master --show-md >> report.md
          cml-publish siamese_logs.html >> report.md

          cml-send-comment report.md
