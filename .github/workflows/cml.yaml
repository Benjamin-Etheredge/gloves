name: testing
on: [push]
jobs:
  run:
    runs-on: [self-hosted, big-gpu, cml]
    environment: test
    
    steps:
      - uses: actions/checkout@v2
      - name: cml_run
        shell: bash
        env:
          repo_token: ${{ secrets.GITHUB_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID}}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          MLFLOW_S3_ENDPOINT_URL: ${{ secrets.MLFLOW_S3_ENDPOINT_URL }}
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_TRACKING_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_TRACKING_PASSWORD }}
        run: |
          # Install requirements
          pip install dvc boto3

          # No need to install other reqs as runs are done in docker

          # Pull data & run-cache from S3 and reproduce pipeline
          dvc pull -d --run-cache siamese@distance
          dvc repro siamese@distance
          dvc push

         scripts/distance_report.sh >> report.md
         cml-send-comment report.md
        
