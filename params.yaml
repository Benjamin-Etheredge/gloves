#out_dir: /nfs/data/gloves
#- docker_cmd: docker run -v $(pwd)/outputs:/outputs
# TODO fix this absolute path
#out_dir: /nfs/data/gloves/outputs
out_dir: artifacts
docker_out_dir: /outputs
#docker_cmd: docker run -v /nfs/data/gloves/outputs:/outputs
docker_cmd: docker run -v ${PWD}/artifacts:/outputs --user 1000:1000

wget:
  img: etheredgeb/wget_url:latest
  data_url: "https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz"
  out_dir: wget

untar:
  img: etheredgeb/untar_data:latest
  tar_args: xzvf
  data_dir: untar
  tar_file_name: images.tar.gz
  
clean:
  img: etheredgeb/clean_oxford_pet_data:latest
  out_dir: clean

split: 
  img: etheredgeb/split_oxford_pet_data:latest
  train_dir: train
  test_dir: test
  ratio: 0.1

train:
  img: etheredgeb/gloves:latest
  docker_args: >-
        --gpus all
        -e TF_FORCE_GPU_ALLOW_GROWTH=true 
        -e MLFLOW_EXPERIMENT_NAME=gloves
        -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
        -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
        -e MLFLOW_S3_ENDPOINT_URL=$MLFLOW_S3_ENDPOINT_URL
        -e MLFLOW_TRACKING_URI=$MLFLOW_TRACKING_URI
        -e MLFLOW_TRACKING_USERNAME=$MLFLOW_TRACKING_USERNAME
        -e MLFLOW_TRACKING_PASSWORD=$MLFLOW_TRACKING_PASSWORD
        -e S3_ENDPOINT=$S3_ENDPOINT

  model_dir: models
  model_filename: model
  encoder: models/encoder
  # hypers
  epochs: 1

classifier:
  train_dir: train
  test_dir: train
  model_dir: classifier_models
  model_filename: model
  label_encoder: label_encoder
  encoder: models/encoder
  # hypers
  epochs: 1
